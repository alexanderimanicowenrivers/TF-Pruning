{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST-Prune.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexanderimanicowenrivers/TF-Pruning/blob/master/MNIST_Prune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "onXwj-Mxblkg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Intro "
      ]
    },
    {
      "metadata": {
        "id": "HZ9PK-6XZ36u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this colab document we will explore how to create and prune a basic model in tensorflow.\n"
      ]
    },
    {
      "metadata": {
        "id": "qn3nWaMHboup",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Imports & utils"
      ]
    },
    {
      "metadata": {
        "id": "7_JNrbEeYeuz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "import tensorflow.contrib.eager as tfe\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UKYEpps-iGRO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Plot learning curves of experiments\n",
        "def plot_learning_curves(experiment_data):\n",
        "  # Generate figure.\n",
        "  fig, axes = plt.subplots(3, 4, figsize=(22,12))\n",
        "  st = fig.suptitle(\n",
        "      \"Learning Curves for all Tasks and Hyper-parameter settings\",\n",
        "      fontsize=\"x-large\")\n",
        "  # Plot all learning curves.\n",
        "  for i, results in enumerate(experiment_data):\n",
        "    for j, (setting, train_accuracy, test_accuracy) in enumerate(results):\n",
        "      # Plot.\n",
        "      xs = [x * log_period_samples for x in range(1, len(train_accuracy)+1)]\n",
        "      axes[j, i].plot(xs, train_accuracy, label='train_accuracy')\n",
        "      axes[j, i].plot(xs, test_accuracy, label='test_accuracy')\n",
        "      # Prettify individual plots.\n",
        "      axes[j, i].ticklabel_format(style='sci', axis='x', scilimits=(0,0))\n",
        "      axes[j, i].set_xlabel('Number of samples processed')\n",
        "      axes[j, i].set_ylabel('Epochs: {}, Learning rate: {}.  Accuracy'.format(*setting))\n",
        "      axes[j, i].set_title('Task {}'.format(i + 1))\n",
        "      axes[j, i].legend()\n",
        "  # Prettify overall figure.\n",
        "  plt.tight_layout()\n",
        "  st.set_y(0.95)\n",
        "  fig.subplots_adjust(top=0.91)\n",
        "  plt.show()\n",
        "\n",
        "# Generate summary table of results.\n",
        "def plot_summary_table(experiment_data):\n",
        "  # Fill Data.\n",
        "  cell_text = []\n",
        "  rows = []\n",
        "  columns = ['Setting 1', 'Setting 2', 'Setting 3']\n",
        "  for i, results in enumerate(experiment_data):\n",
        "    rows.append('Model {}'.format(i + 1))\n",
        "    cell_text.append([])\n",
        "    for j, (setting, train_accuracy, test_accuracy) in enumerate(results):\n",
        "      cell_text[i].append(test_accuracy[-1])\n",
        "  # Generate Table.\n",
        "  fig=plt.figure(frameon=False)\n",
        "  ax = plt.gca()\n",
        "  the_table = ax.table(\n",
        "      cellText=cell_text,\n",
        "      rowLabels=rows,\n",
        "      colLabels=columns,\n",
        "      loc='center')\n",
        "  the_table.scale(1, 4)\n",
        "  # Prettify.\n",
        "  ax.patch.set_facecolor('None')\n",
        "  ax.xaxis.set_visible(False)\n",
        "  ax.yaxis.set_visible(False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mw0BAG84Y2bW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data loader"
      ]
    },
    {
      "metadata": {
        "id": "s7czD-PNiRT2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Global variables.\n",
        "log_period_samples = 20000\n",
        "batch_size = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9ps_IQMZY_Em",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_data():\n",
        "    return input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a3CkxirMY1JX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "9342a33f-fe66-4806-efca-ee1522e622d1"
      },
      "cell_type": "code",
      "source": [
        "  mnist=get_data()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CsnxVdc0hag3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Store results of runs with different configurations in a dictionary.\n",
        "# Use a tuple (num_epochs, learning_rate) as keys, and a tuple (training_accuracy, testing_accuracy)\n",
        "experiments_task1 = []\n",
        "settings = [(1, 0.005)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T0C6d-7IZDsJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model"
      ]
    },
    {
      "metadata": {
        "id": "kN-D6W57ZEtp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "weight_default_name='weight'\n",
        "bias_default_name='bias'\n",
        "\n",
        "def get_placeholders():\n",
        "  x = tf.placeholder(tf.float32, [None, 784])\n",
        "  y_ = tf.placeholder(tf.float32, [None, 10])\n",
        "  return x, y_\n",
        "\n",
        "def _weight_variable(\n",
        "        shape,\n",
        "        initializer=None,\n",
        "        name=None,\n",
        "        layer_no=0,):\n",
        "    \"\"\"\n",
        "    Returns a weight variable with a given shape.\n",
        "    :param initializer: TensorFlow initializer. Default Xavier.\n",
        "    :param layer: Variable layer number.\n",
        "    :param shape: var shape.\n",
        "    \"\"\"\n",
        "    if name==weight_default_name: \n",
        "      name=weight_default_name+'_'+str(layer_no)\n",
        "      \n",
        "    if initializer is None:\n",
        "        initializer = tf.contrib.layers.xavier_initializer()\n",
        "\n",
        "    var = tf.get_variable(name, shape, initializer=initializer)\n",
        "    return var\n",
        "  \n",
        "def _bias_variable(\n",
        "        shape,\n",
        "        initializer=None,\n",
        "        layer_no=0,\n",
        "):\n",
        "    \"\"\"\n",
        "    Returns a bias variable with a given shape.\n",
        "    :param initializer: TensorFlow initializer. Default zero.\n",
        "    :param layer_no: Variable layer number.\n",
        "    :param shape: Variable shape.\n",
        "    \"\"\"\n",
        "    name=bias_default_name+'_'+str(layer_no)\n",
        "    if initializer is None:\n",
        "        initializer = tf.constant_initializer(0.)\n",
        "\n",
        "    return _weight_variable(shape,\n",
        "                            initializer=initializer,\n",
        "                            name=name)\n",
        "  \n",
        "  \n",
        "def affine(\n",
        "        inp,\n",
        "        units,\n",
        "        bias=True,\n",
        "        W_initializer=None,\n",
        "        b_initializer=None,\n",
        "        W_name=weight_default_name,\n",
        "        bias_name=bias_default_name,\n",
        "        layer_no=0\n",
        "):\n",
        "    \"\"\" Creates an affine layer.\n",
        "    :param inp: Input tensor.\n",
        "    :param units: Number of units.\n",
        "    :param bias: Include bias term.\n",
        "    :param W_initializer: Initializer for the multiplicative weight.\n",
        "    :param b_initializer: Initializer for the bias term.\n",
        "    :param W_name: Name of the weight.\n",
        "    :param bias_name: Name of the bias.\n",
        "    :return: Tensor defined as input.dot(weight) + bias.\n",
        "    \"\"\"\n",
        "    input_size = inp.shape[-1]\n",
        "    W = _weight_variable([input_size, units],\n",
        "                         initializer=W_initializer,\n",
        "                         name=W_name,layer_no=layer_no)\n",
        "\n",
        "    output = tf.matmul(inp, W)\n",
        "\n",
        "    if bias:\n",
        "        b = _bias_variable((units,),\n",
        "                           initializer=b_initializer,\n",
        "                           layer_no=layer_no)\n",
        "\n",
        "        output=tf.add(output, b)\n",
        "\n",
        "    return output\n",
        "  \n",
        "def mlp(inputs,\n",
        "        layer_sizes,\n",
        "        nonlinearity=tf.nn.relu,\n",
        "        output_nonlinearity=None,\n",
        "        W_initializer=None,\n",
        "        b_initializer=None):\n",
        "    \"\"\"\n",
        "    Creates a multi-layer perceptron with given hidden sizes. A nonlinearity\n",
        "    is applied after every hidden layer.\n",
        "    \n",
        "    output shape: N x (number of output units)\n",
        "    :param inputs: List of input tensors.\n",
        "    :param layer_sizes: List of layers sizes, including output layer size.\n",
        "    :param nonlinearity: Hidden layer nonlinearity.\n",
        "    :param output_nonlinearity: Output layer nonlinearity.\n",
        "    :param W_initializer: Weight initializer.\n",
        "    :param b_initializer: Bias initializer.\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    if layer_sizes[-1] is None:\n",
        "        layer_sizes = list(layer_sizes)\n",
        "        layer_sizes[-1] = 1\n",
        "\n",
        "    # Take care of the input layer separately to make use of broadcasting in\n",
        "    # a case of several input tensors.\n",
        "    layer = affine(\n",
        "    inp=inputs,\n",
        "    units=layer_sizes[0],\n",
        "    bias=True,\n",
        "    W_initializer=W_initializer,\n",
        "    b_initializer=b_initializer\n",
        "    )\n",
        "\n",
        "    layer = nonlinearity(layer)\n",
        "\n",
        "    for i_layer, size in enumerate(layer_sizes[1:], 1):\n",
        "\n",
        "      layer = affine(layer, size,\n",
        "                     W_initializer=W_initializer,\n",
        "                     b_initializer=b_initializer,\n",
        "                    layer_no=i_layer)\n",
        "      if i_layer < len(layer_sizes) - 1:\n",
        "          layer = nonlinearity(layer)\n",
        "\n",
        "    return layer\n",
        "  \n",
        "def get_graph(layers):\n",
        "  x, y_ = get_placeholders()\n",
        "  linear=mlp(x,layers)\n",
        "  loss=tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(logits=linear,labels=y_))\n",
        "  opt=tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
        "  correct_prediction = tf.equal(tf.argmax(linear,1), tf.argmax(y_,1))\n",
        "  accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "  \n",
        "  return x, y_,linear,loss,opt,correct_prediction,accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_q0UztOoZG0k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training"
      ]
    },
    {
      "metadata": {
        "id": "WX27U9PcCe18",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "48e4732f-dc99-48ef-8d4e-860be28f53fb"
      },
      "cell_type": "code",
      "source": [
        "print('Training Model 1')\n",
        "layers=[1000, 1000, 500, 200,10]\n",
        "# Train Model 1 with the different hyper-parameter settings.\n",
        "for (num_epochs, learning_rate) in settings:\n",
        "\n",
        "  # Reset graph, recreate placeholders and dataset.\n",
        "  tf.reset_default_graph()\n",
        "  mnist = get_data()\n",
        "  eval_mnist = get_data()\n",
        "\n",
        "  #####################################################\n",
        "  # Define model, loss, update and evaluation metric. #\n",
        "  #####################################################\n",
        "  x, y_,linear,loss,opt,correct_prediction,accuracy=get_graph(layers)\n",
        "  # Train.\n",
        "  i, train_accuracy, test_accuracy = 0, [], []\n",
        "  log_period_updates = int(log_period_samples / batch_size)\n",
        "  saver = tf.train.Saver()\n",
        "  with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    while mnist.train.epochs_completed < num_epochs:\n",
        "      \n",
        "      # Update.\n",
        "      i += 1\n",
        "      batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "      \n",
        "      #################\n",
        "      # Training step #\n",
        "      #################\n",
        "      feed_dict={x:batch_xs,y_:batch_ys}\n",
        "      _=sess.run([opt],feed_dict=feed_dict)\n",
        "      \n",
        "      # Periodically evaluate.\n",
        "      if i % log_period_updates == 0:\n",
        "        \n",
        "        #####################################\n",
        "        # Compute and store train accuracy. #\n",
        "        #####################################\n",
        "        \n",
        "        batch_xs, batch_ys = mnist.train.next_batch((int(mnist.train.labels.shape[0]/5)))\n",
        "        \n",
        "        feed_dict={x:batch_xs,y_:batch_ys}\n",
        "        acc=sess.run([accuracy],feed_dict)\n",
        "        print(f'Accuracy {acc} at iteration {i}')\n",
        "\n",
        "        train_accuracy.append(acc)\n",
        "        #####################################\n",
        "        # Compute and store test accuracy.  #\n",
        "        #####################################\n",
        "    save_path = saver.save(sess, \"./model.ckpt\")\n",
        "\n",
        "    feed_dict={x:eval_mnist.test.images,y_:eval_mnist.test.labels}\n",
        "    acc=sess.run([accuracy],feed_dict)\n",
        "    test_accuracy.append(acc)\n",
        "    print(f'Test Accuracy {acc}')\n",
        "\n",
        "  experiments_task1.append(\n",
        "      ((num_epochs, learning_rate), train_accuracy, test_accuracy))"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Model 1\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "Accuracy [0.93454546] at iteration 200\n",
            "Accuracy [0.9423636] at iteration 400\n",
            "Accuracy [0.9539091] at iteration 600\n",
            "Accuracy [0.96245456] at iteration 800\n",
            "Accuracy [0.9710909] at iteration 1000\n",
            "Accuracy [0.97409093] at iteration 1200\n",
            "Accuracy [0.9703636] at iteration 1400\n",
            "Accuracy [0.9750909] at iteration 1600\n",
            "Accuracy [0.9750909] at iteration 1800\n",
            "Test Accuracy [0.9705]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1baVaSeBPRDM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Restore test"
      ]
    },
    {
      "metadata": {
        "id": "ww1MmQBfHFw9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "adb54494-c34b-4b9f-8227-1e7347128701"
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "x, y_,linear,loss,opt,correct_prediction,accuracy=get_graph(layers)\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  # Restore variables from disk.\n",
        "  saver.restore(sess, \"./model.ckpt\")\n",
        "  print(\"Model restored.\")\n",
        "  # Check the values of the variables\n",
        "  batch_xs, batch_ys = mnist.train.next_batch((int(mnist.train.labels.shape[0]/5)))\n",
        "  feed_dict={x:batch_xs,y_:batch_ys}\n",
        "  acc=sess.run([accuracy],feed_dict)\n",
        "  print(f'Accuracy {acc} at iteration {i}')\n",
        "  total_parameters = 0\n",
        "  print(f'{tf.trainable_variables()}')\n",
        "  for variable in tf.trainable_variables():\n",
        "      # shape is an array of tf.Dimension\n",
        "      shape = variable.get_shape()\n",
        "      variable_parameters = 1\n",
        "      for dim in shape:\n",
        "          variable_parameters *= dim.value\n",
        "      total_parameters += variable_parameters\n",
        "  print(\"total parameters\",total_parameters)"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./model.ckpt\n",
            "Model restored.\n",
            "Accuracy [0.9780909] at iteration 1800\n",
            "[<tf.Variable 'weight_0:0' shape=(784, 1000) dtype=float32_ref>, <tf.Variable 'bias_0:0' shape=(1000,) dtype=float32_ref>, <tf.Variable 'weight_1:0' shape=(1000, 1000) dtype=float32_ref>, <tf.Variable 'bias_1:0' shape=(1000,) dtype=float32_ref>, <tf.Variable 'weight_2:0' shape=(1000, 500) dtype=float32_ref>, <tf.Variable 'bias_2:0' shape=(500,) dtype=float32_ref>, <tf.Variable 'weight_3:0' shape=(500, 200) dtype=float32_ref>, <tf.Variable 'bias_3:0' shape=(200,) dtype=float32_ref>, <tf.Variable 'weight_4:0' shape=(200, 10) dtype=float32_ref>, <tf.Variable 'bias_4:0' shape=(10,) dtype=float32_ref>]\n",
            "total parameters 2388710\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "51maYRzjZIYi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Pruning"
      ]
    },
    {
      "metadata": {
        "id": "baG7zqZ9SdNh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "k=[0, 25, 50, 60, 70, 80, 90, 95, 97, 99]\n",
        "type_prunes=['unit','weight']\n",
        "\n",
        "#prune with lowest l1 norm sum "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jK-SdV92bi-5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b6B8fxaQZJRy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 980
        },
        "outputId": "4a812b96-3d8a-4175-b4ad-c4b7ee68fef8"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "tf.reset_default_graph()\n",
        "x, y_,linear,loss,opt,correct_prediction,accuracy=get_graph(layers)\n",
        "\n",
        "saver = tf.train.Saver()\n",
        "type_prune='weight'\n",
        "\n",
        "print(total_parameters, \"Total parameters to prune\")\n",
        "accs=[]\n",
        "params=[]\n",
        "with tf.Session() as sess:\n",
        "  \n",
        "  for type_prune in type_prunes:\n",
        "    params_pruned=0.\n",
        "    param_prune_count=[]\n",
        "    acc_list=[]\n",
        "\n",
        "  # Restore variables from disk.\n",
        "    saver.restore(sess, \"./model.ckpt\")\n",
        "    print(\"Model restored.\")\n",
        "    # Check the values of the variables\n",
        "    all_vars = tf.trainable_variables()\n",
        "    feed_dict={x:eval_mnist.test.images,y_:eval_mnist.test.labels}\n",
        "  \n",
        "    if type_prune=='unit':\n",
        "      axis_sum=0 #add on abs of bias's \n",
        "    else: \n",
        "      axis_sum=1\n",
        "\n",
        "    while params_pruned<total_parameters:\n",
        "\n",
        "      #Evaluate \n",
        "      acc=sess.run(accuracy,feed_dict)\n",
        "      param_prune_count.append(params_pruned)\n",
        "      acc_list.append(acc)\n",
        "      print(params_pruned, \"paramns pruned\")\n",
        "      #Prune \n",
        "      var_mag=np.array([])\n",
        "      layer_sizes=[]\n",
        "      var_sizes=[]\n",
        "      for var_num,variable in enumerate(all_vars):\n",
        "        if 'weight' in variable.name and str(len(layers)-1) not in variable.name: #leave out last layer \n",
        "          var_sizes.append(variable.shape)\n",
        "          layer_sizes.append(variable.shape[1-axis_sum].value)\n",
        "          if type_prune=='unit':\n",
        "            unit_vals=tf.reduce_sum(tf.math.abs(variable),axis=axis_sum).eval()+tf.reduce_sum(tf.math.abs(all_vars[var_num+1]),axis=axis_sum).eval()\n",
        "            var_mag=np.concatenate((var_mag,unit_vals),axis=0)\n",
        "          else: \n",
        "            var_mag=np.concatenate((var_mag,tf.reduce_sum(tf.math.abs(variable),axis=axis_sum).eval()),axis=0)\n",
        "\n",
        "      all_concat=np.reshape(np.array(var_mag),((-1,)))\n",
        "      prune_indx=np.argmin(all_concat)\n",
        "\n",
        "      cum_sum_ind=np.cumsum(layer_sizes)\n",
        "      for idx,lens in enumerate(cum_sum_ind):\n",
        "        if prune_indx<lens:\n",
        "          prun_ind=lens-prune_indx\n",
        "          if type_prune=='unit':\n",
        "\n",
        "            mask=np.ones(var_sizes[idx])*1.0\n",
        "            mask[:,idx]=0\n",
        "\n",
        "            maskb=np.ones(var_sizes[idx][1])*1.0\n",
        "            maskb[idx]=0\n",
        "\n",
        "\n",
        "            w_ind=idx*2\n",
        "            assign_op1=all_vars[w_ind].assign(all_vars[w_ind]*mask)\n",
        "            assign_op2=all_vars[w_ind+1].assign(all_vars[w_ind+1]*maskb)\n",
        "            assign_op=[assign_op1,assign_op2]\n",
        "\n",
        "            params_pruned+=var_sizes[idx][0]+1\n",
        "\n",
        "          else: \n",
        "            mask=np.ones(var_sizes[idx])*1.0\n",
        "            mask[idx]=0\n",
        "            w_ind=idx*2\n",
        "            assign_op=all_vars[w_ind].assign(all_vars[w_ind]*mask)\n",
        "            params_pruned+=var_sizes[idx][1]+1\n",
        "\n",
        "      sess.run(assign_op)\n",
        "\n",
        "      #Train \n",
        "      mnist.train._epochs_completed = 0\n",
        "      mnist.train._index_in_epoch = 0\n",
        "      while mnist.train.epochs_completed < num_epochs:\n",
        "        # Update.\n",
        "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "\n",
        "        #################\n",
        "        # Training step #\n",
        "        #################\n",
        "        feed_dict={x:batch_xs,y_:batch_ys}\n",
        "        _=sess.run([opt],feed_dict=feed_dict)\n",
        "        \n",
        "    accs.append(acc_list)\n",
        "    params.append(param_prune_count)"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2388710 Total parameters to prune\n",
            "INFO:tensorflow:Restoring parameters from ./model.ckpt\n",
            "Model restored.\n",
            "0.0 paramns pruned\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-206-1e6f28ec0c32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;31m#################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_ys\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "HlUYKWEjTeXq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "begin_pruning_step = 0\n",
        "end_pruning_step = 250\n",
        "pruning_frequency = 1\n",
        "sparsity_function_end_step = 250\n",
        "target_sparsity = .9"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gdxTTrZuZKN8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Analysis"
      ]
    },
    {
      "metadata": {
        "id": "LubkBwM9ZLUd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}